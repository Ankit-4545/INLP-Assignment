{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c7e2b41-1094-41c7-a2dc-57d5fa6cd683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "755cb6d5-301a-426e-816a-2be48c2cb40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en=pd.read_json('OneDrive_1_22-1-2026/cc100_en.jsonl',lines=True)\n",
    "df_mn=pd.read_json('OneDrive_1_22-1-2026/cc100_mn.jsonl',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1f5d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=int(df_en.shape[0]*0.8)\n",
    "test_size=int(df_en.shape[0]*0.1)\n",
    "val_size=int(df_en.shape[0]*0.1)\n",
    "df_en_train=df_en[\"text\"][:train_size]\n",
    "df_en_test=df_en[\"text\"][train_size:train_size+test_size]\n",
    "df_en_val=df_en[\"text\"][train_size+test_size:train_size+test_size+val_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddc52385-8347-469c-92ca-ddb214ef819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove extra white spaces\n",
    "def white_space_remover(text):\n",
    "    return \" \".join(text.strip().split())   \n",
    "df_en[\"text\"]=df_en[\"text\"].apply(white_space_remover)\n",
    "df_mn[\"text\"]=df_mn[\"text\"].apply(white_space_remover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31aebe91-f322-405f-afef-539b5fdd914e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Belmont Estate is on the market for $63 millio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“Within the city we’ve had homes that have sol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The three-storey home has five bedrooms, twelv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Surrounding the property is a Versailles-inspi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to Frosch, the listing has received ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Belmont Estate is on the market for $63 millio...\n",
       "1  “Within the city we’ve had homes that have sol...\n",
       "2  The three-storey home has five bedrooms, twelv...\n",
       "3  Surrounding the property is a Versailles-inspi...\n",
       "4  According to Frosch, the listing has received ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb28e8d7-5ee5-45ca-8466-55b3a12386f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Түмэнбаярын Бум-Эрдэнэ: “Дотроосоо” - 2 (Өгүүл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Маш их таалагдлаа</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Хэцүү юмдаа, хүний амьдрал. Хажуудаа жаргал нь...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>хаа очиж аймшгийн байсан амьдрал ингэж нэг хэв...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Бум ахын өгүүллэгүүд яг л хуучны кино шиг сана...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Түмэнбаярын Бум-Эрдэнэ: “Дотроосоо” - 2 (Өгүүл...\n",
       "1                                  Маш их таалагдлаа\n",
       "2  Хэцүү юмдаа, хүний амьдрал. Хажуудаа жаргал нь...\n",
       "3  хаа очиж аймшгийн байсан амьдрал ингэж нэг хэв...\n",
       "4  Бум ахын өгүүллэгүүд яг л хуучны кино шиг сана..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddfa47dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer function using white space\n",
    "def white_space_tokenizer(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd6760a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lis=[]\n",
    "for i in range(len(df_en)):\n",
    "    lis.append(white_space_tokenizer(df_en[\"text\"].iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ce15d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex Tokenizer function\n",
    "def regex_tokenizer(text):\n",
    "    # First, normalize number formatting: replace spaces between digits with nothing\n",
    "    # This converts \"22 000\" or \"1 28\" patterns to \"22000\" or \"128\"\n",
    "    text = re.sub(r'(\\d)\\s+(?=\\d)', r'\\1', text)\n",
    "    \n",
    "    # Pattern explanation:\n",
    "    # \\d{1,3}(?:,\\d{3})+(?:\\.\\d+)? - matches numbers with commas (e.g., 22,000)\n",
    "    # \\b\\w+(?:'\\w+)? - matches words with optional apostrophes (for contractions like \"don't\")\n",
    "    # \\d+(?:\\.\\d+)? - matches numbers including decimals\n",
    "    # (?<=[a-zA-Z])[.!?;:,] - matches punctuation that follows letters\n",
    "    # [-–—] - matches various dash types\n",
    "    pattern = r\"\\d{1,3}(?:,\\d{3})+(?:\\.\\d+)?|\\b\\w+(?:'\\w+)?\\b|\\d+(?:\\.\\d+)?|(?<=[a-zA-Z])[.!?;:,]|[-–—]\"\n",
    "    \n",
    "    tokens = re.findall(pattern, text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc15a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bpe(corpus, num_merges=200):\n",
    "    vocab = defaultdict(int)\n",
    "\n",
    "    # Build initial vocab\n",
    "    for sentence in corpus:\n",
    "        for word in sentence.split():\n",
    "            vocab[tuple(word) + (\"</w>\",)] += 1\n",
    "\n",
    "    merges = []\n",
    "\n",
    "    for _ in range(num_merges):\n",
    "        pair_freq = defaultdict(int)\n",
    "\n",
    "        # Count adjacent pairs\n",
    "        for tokens, freq in vocab.items():\n",
    "            for i in range(len(tokens) - 1):\n",
    "                pair_freq[(tokens[i], tokens[i + 1])] += freq\n",
    "\n",
    "        if not pair_freq:\n",
    "            break\n",
    "\n",
    "        best_pair = max(pair_freq, key=pair_freq.get)\n",
    "\n",
    "        # Early stopping\n",
    "        if pair_freq[best_pair] < 2:\n",
    "            break\n",
    "\n",
    "        merges.append(best_pair)\n",
    "\n",
    "        new_vocab = defaultdict(int)\n",
    "\n",
    "        for tokens, freq in vocab.items():\n",
    "            new_tokens = []\n",
    "            i = 0\n",
    "            while i < len(tokens):\n",
    "                if i < len(tokens) - 1 and tokens[i] == best_pair[0] and tokens[i + 1] == best_pair[1]:\n",
    "                    new_tokens.append(tokens[i] + tokens[i + 1])\n",
    "                    i += 2\n",
    "                else:\n",
    "                    new_tokens.append(tokens[i])\n",
    "                    i += 1\n",
    "\n",
    "            new_vocab[tuple(new_tokens)] += freq\n",
    "\n",
    "        vocab = new_vocab\n",
    "\n",
    "    return merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdfe293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bpe(text, merges):\n",
    "    \"\"\"\n",
    "    text: input sentence (string)\n",
    "    merges: list of BPE merge rules learned from training\n",
    "    returns: list of BPE tokens\n",
    "    \"\"\"\n",
    "\n",
    "    output_tokens = []\n",
    "\n",
    "    words = text.split()\n",
    "\n",
    "    for word in words:\n",
    "        tokens = list(word) + ['</w>']\n",
    "\n",
    "        for merge in merges:\n",
    "            i = 0\n",
    "            new_tokens = []\n",
    "            while i < len(tokens):\n",
    "                if i < len(tokens) - 1 and (tokens[i], tokens[i + 1]) == merge:\n",
    "                    new_tokens.append(tokens[i] + tokens[i + 1])\n",
    "                    i += 2\n",
    "                else:\n",
    "                    new_tokens.append(tokens[i])\n",
    "                    i += 1\n",
    "            tokens = new_tokens\n",
    "\n",
    "        # Remove end-of-word marker\n",
    "        if tokens[-1] == '</w>':\n",
    "            tokens = tokens[:-1]\n",
    "\n",
    "        output_tokens.extend(tokens)\n",
    "\n",
    "    return output_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a0bbaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train_bpe(df_en_train, num_merges=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3f3e306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how</w>', 'are</w>', 'you</w>']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "apply_bpe(\"how are you\",train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84e1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
